{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "pyspark_submit_args = '--packages org.mongodb.spark:mongo-spark-connector_2.11:2.4.0 pyspark-shell'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"h6\")\\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://54.186.55.238/mydb4.air\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df2 = df.withColumn(\"aqi_co\", df[\"aqi_co\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"aqi_no2\", df[\"aqi_no2\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"aqi_o3\", df[\"aqi_o3\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"aqi_so2\", df[\"aqi_so2\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"aqi_pm10\", df[\"aqi_pm10\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_co\", df[\"arithmetic_mean_co\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_no2\", df[\"arithmetic_mean_no2\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_o3\", df[\"arithmetic_mean_o3\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"max_aqi\", df[\"max_aqi\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"state_code\", df[\"state_code\"].cast(StringType()))\\\n",
    "        .withColumn(\"aqi_pm25_frm\", df[\"aqi_pm25_frm\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"aqi_pm25_nonfrm\", df[\"aqi_pm25_nonfrm\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"aqi_pm25_speciation\", df[\"aqi_pm25_speciation\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_pressure\", df[\"arithmetic_mean_pressure\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_wind\", df[\"arithmetic_mean_wind\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_so2\", df[\"arithmetic_mean_so2\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_pm10\", df[\"arithmetic_mean_pm10\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_pm25_frm\", df[\"arithmetic_mean_pm25_frm\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_pm25_nonfrm\", df[\"arithmetic_mean_pm25_nonfrm\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_pm25_speciation\", df[\"arithmetic_mean_pm25_speciation\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_temperature\", df[\"arithmetic_mean_temperature\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"date_local\", df[\"date_local\"].cast(StringType()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "common_key1 = ['county_code','city_name','county_name','date_local']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_id',\n",
       " 'aqi_co',\n",
       " 'aqi_no2',\n",
       " 'aqi_o3',\n",
       " 'aqi_pm10',\n",
       " 'aqi_pm25_frm',\n",
       " 'aqi_pm25_nonfrm',\n",
       " 'aqi_pm25_speciation',\n",
       " 'aqi_so2',\n",
       " 'arithmetic_mean_co',\n",
       " 'arithmetic_mean_no2',\n",
       " 'arithmetic_mean_o3',\n",
       " 'arithmetic_mean_pm10',\n",
       " 'arithmetic_mean_pm25_frm',\n",
       " 'arithmetic_mean_pm25_nonfrm',\n",
       " 'arithmetic_mean_pm25_speciation',\n",
       " 'arithmetic_mean_pressure',\n",
       " 'arithmetic_mean_so2',\n",
       " 'arithmetic_mean_temperature',\n",
       " 'arithmetic_mean_wind',\n",
       " 'cbsa_name',\n",
       " 'city_name',\n",
       " 'county_code',\n",
       " 'county_name',\n",
       " 'date_local',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'max_aqi',\n",
       " 'site_num',\n",
       " 'state_code']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "df3 = df2.groupBy(common_key1)\\\n",
    "   .agg(F.max(\"aqi_co\").alias(\"aqi_co\"),\n",
    "        F.max(\"aqi_no2\").alias(\"aqi_no2\"),\n",
    "        F.max(\"aqi_o3\").alias(\"aqi_o3\"),\n",
    "        F.max(\"aqi_so2\").alias(\"aqi_so2\"),\n",
    "        F.max(\"aqi_pm10\").alias(\"aqi_pm10\"),\n",
    "        F.max(\"arithmetic_mean_co\").alias(\"arithmetic_mean_co\"),\n",
    "        F.max(\"arithmetic_mean_no2\").alias(\"arithmetic_mean_no2\"),\n",
    "        F.max(\"arithmetic_mean_o3\").alias(\"arithmetic_mean_o3\"),\n",
    "        F.max(\"max_aqi\").alias(\"max_aqi\"),\n",
    "        F.max(\"aqi_pm25_frm\").alias(\"aqi_pm25_frm\"),\n",
    "        F.max(\"aqi_pm25_nonfrm\").alias(\"aqi_pm25_nonfrm\"),\n",
    "        F.max(\"aqi_pm25_speciation\").alias(\"aqi_pm25_speciation\"),\n",
    "        F.max(\"arithmetic_mean_pressure\").alias(\"arithmetic_mean_pressure\"),\n",
    "        F.max(\"arithmetic_mean_wind\").alias(\"arithmetic_mean_wind\"),\n",
    "        F.max(\"arithmetic_mean_so2\").alias(\"arithmetic_mean_so2\"),\n",
    "        F.max(\"arithmetic_mean_pm10\").alias(\"arithmetic_mean_pm10\"),\n",
    "        F.max(\"arithmetic_mean_pm25_frm\").alias(\"arithmetic_mean_pm25_frm\"),\n",
    "        F.max(\"arithmetic_mean_pm25_nonfrm\").alias(\"arithmetic_mean_pm25_nonfrm\"),\n",
    "        F.max(\"arithmetic_mean_pm25_speciation\").alias(\"arithmetic_mean_pm25_speciation\"),\n",
    "        F.max(\"arithmetic_mean_temperature\").alias(\"arithmetic_mean_temperature\"),\n",
    "        F.mean(\"latitude\").alias(\"latitude\"),\n",
    "        F.mean(\"longitude\").alias(\"longitude\"))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_key = ['county_code','city_name','county_name']\n",
    "\n",
    "df4 = df3.select('city_name','county_name','county_code','date_local','max_aqi','latitude','longitude',\n",
    "                 lag('max_aqi',2).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_2_max_aqi'),\n",
    "                 lag('max_aqi',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_max_aqi'),\n",
    "                 lag('aqi_co',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_co'),\n",
    "                 lag('aqi_no2',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_no2'),\n",
    "                 lag('aqi_o3',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_o3'),\n",
    "                 lag('aqi_pm10',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_pm10'),\n",
    "                 lag('aqi_pm25_frm',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_pm25_frm'),\n",
    "                 lag('aqi_pm25_nonfrm',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_pm25_nonfrm'),\n",
    "                 lag('aqi_pm25_speciation',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_pm25_speciation'),\n",
    "                 lag('aqi_so2',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_so2'),\n",
    "                 lag('arithmetic_mean_co',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_co'),\n",
    "                 lag('arithmetic_mean_no2',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_no2'),\n",
    "                 lag('arithmetic_mean_o3',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_o3'),\n",
    "                 lag('arithmetic_mean_pm10',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_pm10'),\n",
    "                 lag('arithmetic_mean_pm25_frm',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_pm25_frm'),\n",
    "                 lag('arithmetic_mean_pm25_nonfrm',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_pm25_nonfrm'),\n",
    "                 lag('arithmetic_mean_pm25_speciation',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_pm25_speciation'),\n",
    "                 lag('arithmetic_mean_pressure',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_pressure'),\n",
    "                 lag('arithmetic_mean_so2',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_so2'),\n",
    "                 lag('arithmetic_mean_temperature',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_temperature'),\n",
    "                 lag('arithmetic_mean_wind',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_wind'),\n",
    "                 lead('max_aqi',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('label')\n",
    "                ).persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This should be the table we can model on\n",
    "df5 = df4.withColumn(\"trend1\", col(\"max_aqi\")/col(\"lag_1_max_aqi\"))\\\n",
    "         .withColumn(\"trend2\",col(\"max_aqi\")/col(\"lag_2_max_aqi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city_name',\n",
       " 'county_name',\n",
       " 'county_code',\n",
       " 'date_local',\n",
       " 'max_aqi',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'lag_2_max_aqi',\n",
       " 'lag_1_max_aqi',\n",
       " 'lag_1_aqi_co',\n",
       " 'lag_1_aqi_no2',\n",
       " 'lag_1_aqi_o3',\n",
       " 'lag_1_aqi_pm10',\n",
       " 'lag_1_aqi_pm25_frm',\n",
       " 'lag_1_aqi_pm25_nonfrm',\n",
       " 'lag_1_aqi_pm25_speciation',\n",
       " 'lag_1_aqi_so2',\n",
       " 'lag_1_arithmetic_mean_co',\n",
       " 'lag_1_arithmetic_mean_no2',\n",
       " 'lag_1_arithmetic_mean_o3',\n",
       " 'lag_1_arithmetic_mean_pm10',\n",
       " 'lag_1_arithmetic_mean_pm25_frm',\n",
       " 'lag_1_arithmetic_mean_pm25_nonfrm',\n",
       " 'lag_1_arithmetic_mean_pm25_speciation',\n",
       " 'lag_1_arithmetic_mean_pressure',\n",
       " 'lag_1_arithmetic_mean_so2',\n",
       " 'lag_1_arithmetic_mean_temperature',\n",
       " 'lag_1_arithmetic_mean_wind',\n",
       " 'label',\n",
       " 'trend1',\n",
       " 'trend2']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------+----------+-------+------------------+-----------+-------------+-------------+------------+-------------+------------+--------------+------------------+---------------------+-------------------------+-------------+------------------------+-------------------------+------------------------+--------------------------+------------------------------+---------------------------------+-------------------------------------+------------------------------+-------------------------+---------------------------------+--------------------------+-----+------+------+\n",
      "|  city_name|county_name|county_code|date_local|max_aqi|          latitude|  longitude|lag_2_max_aqi|lag_1_max_aqi|lag_1_aqi_co|lag_1_aqi_no2|lag_1_aqi_o3|lag_1_aqi_pm10|lag_1_aqi_pm25_frm|lag_1_aqi_pm25_nonfrm|lag_1_aqi_pm25_speciation|lag_1_aqi_so2|lag_1_arithmetic_mean_co|lag_1_arithmetic_mean_no2|lag_1_arithmetic_mean_o3|lag_1_arithmetic_mean_pm10|lag_1_arithmetic_mean_pm25_frm|lag_1_arithmetic_mean_pm25_nonfrm|lag_1_arithmetic_mean_pm25_speciation|lag_1_arithmetic_mean_pressure|lag_1_arithmetic_mean_so2|lag_1_arithmetic_mean_temperature|lag_1_arithmetic_mean_wind|label|trend1|trend2|\n",
      "+-----------+-----------+-----------+----------+-------+------------------+-----------+-------------+-------------+------------+-------------+------------+--------------+------------------+---------------------+-------------------------+-------------+------------------------+-------------------------+------------------------+--------------------------+------------------------------+---------------------------------+-------------------------------------+------------------------------+-------------------------+---------------------------------+--------------------------+-----+------+------+\n",
      "|Albuquerque| Bernalillo|          1|2017-03-15|   45.0|35.144450000000006|-106.575605|         null|         null|        null|         null|        null|          null|              null|                 null|                     null|         null|                    null|                     null|                    null|                      null|                          null|                             null|                                 null|                          null|                     null|                             null|                      null| null|  null|  null|\n",
      "|Albuquerque| Bernalillo|          1|2017-05-01|   46.0|35.144450000000006|-106.575605|         null|         null|        null|         null|        null|          null|              null|                 null|                     null|         null|                    null|                     null|                    null|                      null|                          null|                             null|                                 null|                          null|                     null|                             null|                      null| null|  null|  null|\n",
      "+-----------+-----------+-----------+----------+-------+------------------+-----------+-------------+-------------+------------+-------------+------------+--------------+------------------+---------------------+-------------------------+-------------+------------------------+-------------------------+------------------------+--------------------------+------------------------------+---------------------------------+-------------------------------------+------------------------------+-------------------------+---------------------------------+--------------------------+-----+------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cols = ['latitude',\n",
    " 'longitude',\n",
    " 'lag_2_max_aqi',\n",
    " 'lag_1_max_aqi',\n",
    " 'lag_1_aqi_co',\n",
    " 'lag_1_aqi_no2',\n",
    " 'lag_1_aqi_o3',\n",
    " 'lag_1_aqi_pm10',\n",
    " 'lag_1_aqi_pm25_frm',\n",
    " 'lag_1_aqi_pm25_nonfrm',\n",
    " 'lag_1_aqi_pm25_speciation',\n",
    " 'lag_1_aqi_so2',\n",
    " 'lag_1_arithmetic_mean_co',\n",
    " 'lag_1_arithmetic_mean_no2',\n",
    " 'lag_1_arithmetic_mean_o3',\n",
    " 'lag_1_arithmetic_mean_pm10',\n",
    " 'lag_1_arithmetic_mean_pm25_frm',\n",
    " 'lag_1_arithmetic_mean_pm25_nonfrm',\n",
    " 'lag_1_arithmetic_mean_pm25_speciation',\n",
    " 'lag_1_arithmetic_mean_pressure',\n",
    " 'lag_1_arithmetic_mean_so2',\n",
    " 'lag_1_arithmetic_mean_temperature',\n",
    " 'lag_1_arithmetic_mean_wind',\n",
    " 'trend1',\n",
    " 'trend2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging the data with Vector Assembler.\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "va = VectorAssembler(outputCol=\"features\", \n",
    "                     inputCols= feat_cols) #except the last col.\n",
    "points = va.transform(df5).select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-10a67cad6efc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/anaconda3/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \"\"\"\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1286\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/mnt/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "points.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|label|            features|\n",
      "+------------------+-----+--------------------+\n",
      "| 6.850155673906531|  0.0|(25,[0,1],[20.869...|\n",
      "| 6.850155673906531| 33.0|(25,[0,1],[29.566...|\n",
      "| 6.850155673906531| 25.0|(25,[0,1],[39.044...|\n",
      "|49.060331050213144| 90.0|(25,[0,1,2,3,4,6,...|\n",
      "|42.616309976261604| 49.0|(25,[0,1,2,3,4,6,...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 16.9736\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "\n",
    "\n",
    "(trainingData, testData) = points.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(featuresCol='features')\n",
    "\n",
    "# Chain indexer and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestRegressionModel (uid=RandomForestRegressor_e278a4050029) with 20 trees]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfModel = model.stages\n",
    "rfModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gradient boosted regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|label|            features|\n",
      "+------------------+-----+--------------------+\n",
      "| 8.674398254893196| 25.0|(25,[0,1],[39.044...|\n",
      "|45.076324372669056| 61.0|(25,[0,1,2,3,4,6,...|\n",
      "| 50.96604260026299| 90.0|(25,[0,1,2,3,4,6,...|\n",
      "| 45.06403905726718| 49.0|(25,[0,1,2,3,4,6,...|\n",
      "| 46.32391912756721| 48.0|(25,[0,1,2,3,4,6,...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 16.7004\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(points)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = points.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTRegressor(featuresCol=\"indexedFeatures\", maxIter=10)\n",
    "\n",
    "# Chain indexer and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, gbt])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbtModel = model.stages\n",
    "print(gbtModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|label|            features|\n",
      "+------------------+-----+--------------------+\n",
      "| 48.44707478286031| 43.0|(25,[0,1,2,3,4,6,...|\n",
      "|34.344694824779104| 61.0|(25,[0,1,2,3,4,6,...|\n",
      "| 42.97795781771807| 49.0|(25,[0,1,2,3,4,6,...|\n",
      "| 33.82344034699529| 32.0|(25,[0,1,2,3,4,6,...|\n",
      "| 48.56787529106251| 56.0|(25,[0,1,2,3,4,6,...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 29.2 ms, sys: 9.51 ms, total: 38.7 ms\n",
      "Wall time: 9.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "(trainingData, testData) = points.randomSplit([0.7, 0.3])\n",
    "\n",
    "\n",
    "glr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\", maxIter=10, regParam=0.3)\n",
    "\n",
    "# Fit the model\n",
    "model = glr.fit(trainingData)\n",
    "\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.282204923815453\n"
     ]
    }
   ],
   "source": [
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Standard Errors: [0.004568040400879666, 0.0014871929388381047, 0.001484891172149681, 0.0022384439061993804, 0.04282426650590862, 0.00863096371490406, 0.0032719989628260484, 0.008537108154305889, 0.003716867170041703, 0.0028065298044307064, inf, 0.0047288031997156435, 0.6837661971612188, 0.015985919171721034, 3.833739638776442, 0.007316721161005434, 0.012281027870125145, 0.007462366203326255, 0.0003275302824165198, 3.0801268015344454e-05, 0.016345494311850447, 0.0011032249410030373, 0.000623303551940379, 0.014775824549233072, 0.012147544212385166, 0.22332216788275847]\n",
      "T Values: [-22.52880331282746, -52.814844270809566, 130.51278177163414, 117.06806269887257, -1.1192841377833957, 5.2446007440106035, 26.196904923327278, -19.4493667648788, 18.97521813940085, 13.831348580910534, 0.0, -1.5828533696215537, -0.17227555212354245, 7.6663912693500675, 48.72856351650565, 10.408182995441974, 4.3504721157136155, 31.445598119174655, 5.664590329165979, 1.2591599335277721, 7.6403639643567125, -1.4929807600892258, 1.351124097844957, 78.43128232928065, 35.59696300900618, 29.234667326959862]\n",
      "P Values: [0.0, 0.0, 0.0, 0.0, 0.26301942419092916, 1.5667821551268446e-07, 0.0, 0.0, 0.0, 0.0, 1.0, 0.1134554578439122, 0.8632209664387509, 1.7763568394002505e-14, 0.0, 0.0, 1.3586888061523084e-05, 0.0, 1.4744865106663951e-08, 0.2079730987835291, 2.1760371282653068e-14, 0.1354427906695328, 0.17665623305718814, 0.0, 0.0, 0.0]\n",
      "Dispersion: 353.239935147923\n",
      "Null Deviance: 329176704.5284317\n",
      "Residual Degree Of Freedom Null: 556045\n",
      "Deviance: 196408468.74094814\n",
      "Residual Degree Of Freedom: 556020\n",
      "AIC: 4840422.105575814\n",
      "Deviance Residuals: \n",
      "+--------------------+\n",
      "|   devianceResiduals|\n",
      "+--------------------+\n",
      "|  23.052312447459126|\n",
      "| -10.623361795613164|\n",
      "|  -7.803239700621276|\n",
      "| -1.4846137470519452|\n",
      "|  2.8848591538085344|\n",
      "| -15.553834962500531|\n",
      "|  -5.618972857887343|\n",
      "|   6.180196554074286|\n",
      "|  1.8413899717684075|\n",
      "|  -4.268721368715873|\n",
      "|-0.45461057896847024|\n",
      "|  -3.427984910458356|\n",
      "|  -7.740438922804813|\n",
      "|  -7.503976707660719|\n",
      "|  -4.001696028084943|\n",
      "|  -3.368491381388367|\n",
      "|  -3.438319289297965|\n",
      "|   -6.42626771500337|\n",
      "|  27.471826362018355|\n",
      "|  2.3890479496325554|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors))\n",
    "print(\"T Values: \" + str(summary.tValues))\n",
    "print(\"P Values: \" + str(summary.pValues))\n",
    "print(\"Dispersion: \" + str(summary.dispersion))\n",
    "print(\"Null Deviance: \" + str(summary.nullDeviance))\n",
    "print(\"Residual Degree Of Freedom Null: \" + str(summary.residualDegreeOfFreedomNull))\n",
    "print(\"Deviance: \" + str(summary.deviance))\n",
    "print(\"Residual Degree Of Freedom: \" + str(summary.residualDegreeOfFreedom))\n",
    "print(\"AIC: \" + str(summary.aic))\n",
    "print(\"Deviance Residuals: \")\n",
    "summary.residuals().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GeneralizedLinearRegressionTrainingSummary' object has no attribute 'Rmse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-67076a5c0277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GeneralizedLinearRegressionTrainingSummary' object has no attribute 'Rmse'"
     ]
    }
   ],
   "source": [
    "summary.Rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
