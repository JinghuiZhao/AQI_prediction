{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library and Load Data From Mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "pyspark_submit_args = '--packages org.mongodb.spark:mongo-spark-connector_2.11:2.4.0 pyspark-shell'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"aqi\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://54.186.55.238/mydb4.air\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default type is wrong, cast to right type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()\n",
    "df2 = df.withColumn(\"aqi_co\", df[\"aqi_co\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"aqi_no2\", df[\"aqi_no2\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"aqi_o3\", df[\"aqi_o3\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"aqi_so2\", df[\"aqi_so2\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"aqi_pm10\", df[\"aqi_pm10\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_co\", df[\"arithmetic_mean_co\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_no2\", df[\"arithmetic_mean_no2\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_o3\", df[\"arithmetic_mean_o3\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"max_aqi\", df[\"max_aqi\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"state_code\", df[\"state_code\"].cast(StringType()))\\\n",
    "        .withColumn(\"aqi_pm25_frm\", df[\"aqi_pm25_frm\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"aqi_pm25_nonfrm\", df[\"aqi_pm25_nonfrm\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"aqi_pm25_speciation\", df[\"aqi_pm25_speciation\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_pressure\", df[\"arithmetic_mean_pressure\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_wind\", df[\"arithmetic_mean_wind\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_so2\", df[\"arithmetic_mean_so2\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_pm10\", df[\"arithmetic_mean_pm10\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_pm25_frm\", df[\"arithmetic_mean_pm25_frm\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_pm25_nonfrm\", df[\"arithmetic_mean_pm25_nonfrm\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_pm25_speciation\", df[\"arithmetic_mean_pm25_speciation\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"arithmetic_mean_temperature\", df[\"arithmetic_mean_temperature\"].cast(DoubleType()))\\\n",
    "        .withColumn(\"date_local\", df[\"date_local\"].cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- aqi_co: double (nullable = true)\n",
      " |-- aqi_no2: double (nullable = true)\n",
      " |-- aqi_o3: double (nullable = true)\n",
      " |-- aqi_pm10: double (nullable = true)\n",
      " |-- aqi_pm25_frm: double (nullable = true)\n",
      " |-- aqi_pm25_nonfrm: double (nullable = true)\n",
      " |-- aqi_pm25_speciation: double (nullable = true)\n",
      " |-- aqi_so2: double (nullable = true)\n",
      " |-- arithmetic_mean_co: double (nullable = true)\n",
      " |-- arithmetic_mean_no2: double (nullable = true)\n",
      " |-- arithmetic_mean_o3: double (nullable = true)\n",
      " |-- arithmetic_mean_pm10: double (nullable = true)\n",
      " |-- arithmetic_mean_pm25_frm: double (nullable = true)\n",
      " |-- arithmetic_mean_pm25_nonfrm: double (nullable = true)\n",
      " |-- arithmetic_mean_pm25_speciation: double (nullable = true)\n",
      " |-- arithmetic_mean_pressure: double (nullable = true)\n",
      " |-- arithmetic_mean_so2: double (nullable = true)\n",
      " |-- arithmetic_mean_temperature: double (nullable = true)\n",
      " |-- arithmetic_mean_wind: double (nullable = true)\n",
      " |-- cbsa_name: string (nullable = true)\n",
      " |-- city_name: string (nullable = true)\n",
      " |-- county_code: integer (nullable = true)\n",
      " |-- county_name: string (nullable = true)\n",
      " |-- date_local: date (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- max_aqi: double (nullable = true)\n",
      " |-- site_num: integer (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Site-Level Prediction : Random Forest Model (timing with 10,50,100 tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_key = ['county_name','county_code','site_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4 = df2.withColumn('lag_1_aqi',lag('max_aqi',1).over(Window.partitionBy(common_key).orderBy('date_local'))).persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df5 = df4.select(lead('max_aqi',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('label'),\n",
    "                'county_name','county_code','site_num','date_local','max_aqi','latitude','longitude',\n",
    "                  'aqi_co',\n",
    "                 'aqi_no2',\n",
    "                 'aqi_o3',\n",
    "                 'aqi_pm10',\n",
    "                 'aqi_pm25_frm',\n",
    "                 'aqi_pm25_nonfrm',\n",
    "                 'aqi_pm25_speciation',\n",
    "                 'aqi_so2',\n",
    "                 'arithmetic_mean_co',\n",
    "                 'arithmetic_mean_no2',\n",
    "                 'arithmetic_mean_o3',\n",
    "                 'arithmetic_mean_pm10',\n",
    "                 'arithmetic_mean_pm25_frm',\n",
    "                 'arithmetic_mean_pm25_nonfrm',\n",
    "                 'arithmetic_mean_pm25_speciation',\n",
    "                 'arithmetic_mean_pressure',\n",
    "                 'arithmetic_mean_so2',\n",
    "                 'arithmetic_mean_temperature',\n",
    "                 'arithmetic_mean_wind',\n",
    "                 lag('max_aqi',2).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_2_max_aqi'),\n",
    "                 lag('max_aqi',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_max_aqi'),\n",
    "                 lag('aqi_co',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_co'),\n",
    "                 lag('aqi_no2',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_no2'),\n",
    "                 lag('aqi_o3',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_o3'),\n",
    "                 lag('aqi_pm10',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_pm10'),\n",
    "                 lag('aqi_pm25_frm',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_pm25_frm'),\n",
    "                 lag('aqi_pm25_nonfrm',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_pm25_nonfrm'),\n",
    "                 lag('aqi_pm25_speciation',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_pm25_speciation'),\n",
    "                 lag('aqi_so2',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_aqi_so2'),\n",
    "                 lag('arithmetic_mean_co',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_co'),\n",
    "                 lag('arithmetic_mean_no2',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_no2'),\n",
    "                 lag('arithmetic_mean_o3',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_o3'),\n",
    "                 lag('arithmetic_mean_pm10',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_pm10'),\n",
    "                 lag('arithmetic_mean_pm25_frm',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_pm25_frm'),\n",
    "                 lag('arithmetic_mean_pm25_nonfrm',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_pm25_nonfrm'),\n",
    "                 lag('arithmetic_mean_pm25_speciation',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_pm25_speciation'),\n",
    "                 lag('arithmetic_mean_pressure',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_pressure'),\n",
    "                 lag('arithmetic_mean_so2',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_so2'),\n",
    "                 lag('arithmetic_mean_temperature',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_temperature'),\n",
    "                 lag('arithmetic_mean_wind',1).over(Window.partitionBy(common_key).orderBy('date_local')).alias('lag_1_arithmetic_mean_wind'),\n",
    "                ).persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------+-------+----------+-------------+-------------+-----+\n",
      "|county_name|county_code|site_num|max_aqi|date_local|lag_2_max_aqi|lag_1_max_aqi|label|\n",
      "+-----------+-----------+--------+-------+----------+-------------+-------------+-----+\n",
      "|      Allen|          3|       2|   35.0|2017-03-01|         null|         null| 37.0|\n",
      "|      Allen|          3|       2|   37.0|2017-03-02|         null|         35.0| 41.0|\n",
      "|      Allen|          3|       2|   41.0|2017-03-03|         35.0|         37.0| 34.0|\n",
      "|      Allen|          3|       2|   34.0|2017-03-04|         37.0|         41.0| 38.0|\n",
      "|      Allen|          3|       2|   38.0|2017-03-05|         41.0|         34.0| 36.0|\n",
      "|      Allen|          3|       2|   36.0|2017-03-06|         34.0|         38.0| 38.0|\n",
      "|      Allen|          3|       2|   38.0|2017-03-07|         38.0|         36.0| 42.0|\n",
      "|      Allen|          3|       2|   42.0|2017-03-08|         36.0|         38.0| 39.0|\n",
      "|      Allen|          3|       2|   39.0|2017-03-09|         38.0|         42.0| 38.0|\n",
      "|      Allen|          3|       2|   38.0|2017-03-10|         42.0|         39.0| 39.0|\n",
      "|      Allen|          3|       2|   39.0|2017-03-11|         39.0|         38.0| 39.0|\n",
      "|      Allen|          3|       2|   39.0|2017-03-12|         38.0|         39.0| 34.0|\n",
      "|      Allen|          3|       2|   34.0|2017-03-13|         39.0|         39.0| 39.0|\n",
      "|      Allen|          3|       2|   39.0|2017-03-14|         39.0|         34.0| 40.0|\n",
      "|      Allen|          3|       2|   40.0|2017-03-15|         34.0|         39.0| 43.0|\n",
      "|      Allen|          3|       2|   43.0|2017-03-16|         39.0|         40.0| 30.0|\n",
      "|      Allen|          3|       2|   30.0|2017-03-17|         40.0|         43.0| 21.0|\n",
      "|      Allen|          3|       2|   21.0|2017-03-18|         43.0|         30.0| 31.0|\n",
      "|      Allen|          3|       2|   31.0|2017-03-19|         30.0|         21.0| 31.0|\n",
      "|      Allen|          3|       2|   31.0|2017-03-20|         21.0|         31.0| 43.0|\n",
      "|      Allen|          3|       2|   43.0|2017-03-21|         31.0|         31.0| 40.0|\n",
      "|      Allen|          3|       2|   40.0|2017-03-22|         31.0|         43.0| 37.0|\n",
      "|      Allen|          3|       2|   37.0|2017-03-23|         43.0|         40.0| 50.0|\n",
      "|      Allen|          3|       2|   50.0|2017-03-24|         40.0|         37.0| 29.0|\n",
      "|      Allen|          3|       2|   29.0|2017-03-25|         37.0|         50.0| 34.0|\n",
      "|      Allen|          3|       2|   34.0|2017-03-26|         50.0|         29.0| 32.0|\n",
      "|      Allen|          3|       2|   32.0|2017-03-27|         29.0|         34.0| 26.0|\n",
      "|      Allen|          3|       2|   26.0|2017-03-28|         34.0|         32.0| 39.0|\n",
      "|      Allen|          3|       2|   39.0|2017-03-29|         32.0|         26.0| 28.0|\n",
      "|      Allen|          3|       2|   28.0|2017-03-30|         26.0|         39.0| 31.0|\n",
      "|      Allen|          3|       2|   31.0|2017-03-31|         39.0|         28.0| 44.0|\n",
      "|      Allen|          3|       2|   44.0|2017-04-01|         28.0|         31.0| 44.0|\n",
      "|      Allen|          3|       2|   44.0|2017-04-02|         31.0|         44.0| 35.0|\n",
      "|      Allen|          3|       2|   35.0|2017-04-03|         44.0|         44.0| 40.0|\n",
      "|      Allen|          3|       2|   40.0|2017-04-04|         44.0|         35.0| 36.0|\n",
      "|      Allen|          3|       2|   36.0|2017-04-05|         35.0|         40.0| 34.0|\n",
      "|      Allen|          3|       2|   34.0|2017-04-06|         40.0|         36.0| 43.0|\n",
      "|      Allen|          3|       2|   43.0|2017-04-07|         36.0|         34.0| 50.0|\n",
      "|      Allen|          3|       2|   50.0|2017-04-08|         34.0|         43.0| 61.0|\n",
      "|      Allen|          3|       2|   61.0|2017-04-09|         43.0|         50.0| 48.0|\n",
      "|      Allen|          3|       2|   48.0|2017-04-10|         50.0|         61.0| 29.0|\n",
      "|      Allen|          3|       2|   29.0|2017-04-11|         61.0|         48.0| 42.0|\n",
      "|      Allen|          3|       2|   42.0|2017-04-12|         48.0|         29.0| 35.0|\n",
      "|      Allen|          3|       2|   35.0|2017-04-13|         29.0|         42.0| 43.0|\n",
      "|      Allen|          3|       2|   43.0|2017-04-14|         42.0|         35.0| 54.0|\n",
      "|      Allen|          3|       2|   54.0|2017-04-15|         35.0|         43.0| 49.0|\n",
      "|      Allen|          3|       2|   49.0|2017-04-16|         43.0|         54.0| 48.0|\n",
      "|      Allen|          3|       2|   48.0|2017-04-17|         54.0|         49.0| 51.0|\n",
      "|      Allen|          3|       2|   51.0|2017-04-18|         49.0|         48.0| 36.0|\n",
      "|      Allen|          3|       2|   36.0|2017-04-19|         48.0|         51.0| 40.0|\n",
      "|      Allen|          3|       2|   40.0|2017-04-20|         51.0|         36.0| 31.0|\n",
      "|      Allen|          3|       2|   31.0|2017-04-21|         36.0|         40.0| 40.0|\n",
      "|      Allen|          3|       2|   40.0|2017-04-22|         40.0|         31.0| 47.0|\n",
      "|      Allen|          3|       2|   47.0|2017-04-23|         31.0|         40.0| 51.0|\n",
      "|      Allen|          3|       2|   51.0|2017-04-24|         40.0|         47.0| 42.0|\n",
      "|      Allen|          3|       2|   42.0|2017-04-25|         47.0|         51.0| 61.0|\n",
      "|      Allen|          3|       2|   61.0|2017-04-26|         51.0|         42.0| 33.0|\n",
      "|      Allen|          3|       2|   33.0|2017-04-27|         42.0|         61.0| 26.0|\n",
      "|      Allen|          3|       2|   26.0|2017-04-28|         61.0|         33.0| 31.0|\n",
      "|      Allen|          3|       2|   31.0|2017-04-29|         33.0|         26.0| 36.0|\n",
      "|      Allen|          3|       2|   36.0|2017-04-30|         26.0|         31.0| 42.0|\n",
      "|      Allen|          3|       2|   42.0|2017-05-01|         31.0|         36.0| 42.0|\n",
      "|      Allen|          3|       2|   42.0|2017-05-02|         36.0|         42.0| 41.0|\n",
      "|      Allen|          3|       2|   41.0|2017-05-03|         42.0|         42.0| 40.0|\n",
      "|      Allen|          3|       2|   40.0|2017-05-04|         42.0|         41.0| 44.0|\n",
      "|      Allen|          3|       2|   44.0|2017-05-05|         41.0|         40.0| 37.0|\n",
      "|      Allen|          3|       2|   37.0|2017-05-06|         40.0|         44.0| 48.0|\n",
      "|      Allen|          3|       2|   48.0|2017-05-07|         44.0|         37.0| 47.0|\n",
      "|      Allen|          3|       2|   47.0|2017-05-08|         37.0|         48.0| 37.0|\n",
      "|      Allen|          3|       2|   37.0|2017-05-09|         48.0|         47.0| 50.0|\n",
      "|      Allen|          3|       2|   50.0|2017-05-10|         47.0|         37.0| 46.0|\n",
      "|      Allen|          3|       2|   46.0|2017-05-11|         37.0|         50.0| 46.0|\n",
      "|      Allen|          3|       2|   46.0|2017-05-12|         50.0|         46.0| 61.0|\n",
      "|      Allen|          3|       2|   61.0|2017-05-13|         46.0|         46.0| 64.0|\n",
      "|      Allen|          3|       2|   64.0|2017-05-14|         46.0|         61.0| 43.0|\n",
      "|      Allen|          3|       2|   43.0|2017-05-15|         61.0|         64.0| 93.0|\n",
      "|      Allen|          3|       2|   93.0|2017-05-16|         64.0|         43.0| 67.0|\n",
      "|      Allen|          3|       2|   67.0|2017-05-17|         43.0|         93.0| 49.0|\n",
      "|      Allen|          3|       2|   49.0|2017-05-18|         93.0|         67.0| 21.0|\n",
      "|      Allen|          3|       2|   21.0|2017-05-19|         67.0|         49.0| 26.0|\n",
      "|      Allen|          3|       2|   26.0|2017-05-20|         49.0|         21.0| 36.0|\n",
      "|      Allen|          3|       2|   36.0|2017-05-21|         21.0|         26.0| 49.0|\n",
      "|      Allen|          3|       2|   49.0|2017-05-22|         26.0|         36.0| 64.0|\n",
      "|      Allen|          3|       2|   64.0|2017-05-23|         36.0|         49.0| 40.0|\n",
      "|      Allen|          3|       2|   40.0|2017-05-24|         49.0|         64.0| 32.0|\n",
      "|      Allen|          3|       2|   32.0|2017-05-25|         64.0|         40.0| 44.0|\n",
      "|      Allen|          3|       2|   44.0|2017-05-26|         40.0|         32.0| 46.0|\n",
      "|      Allen|          3|       2|   46.0|2017-05-27|         32.0|         44.0| 41.0|\n",
      "|      Allen|          3|       2|   41.0|2017-05-28|         44.0|         46.0| 44.0|\n",
      "|      Allen|          3|       2|   44.0|2017-05-29|         46.0|         41.0| 43.0|\n",
      "|      Allen|          3|       2|   43.0|2017-05-30|         41.0|         44.0| 39.0|\n",
      "|      Allen|          3|       2|   39.0|2017-05-31|         44.0|         43.0| 61.0|\n",
      "|      Allen|          3|       2|   61.0|2017-06-01|         43.0|         39.0| 47.0|\n",
      "|      Allen|          3|       2|   47.0|2017-06-02|         39.0|         61.0|100.0|\n",
      "|      Allen|          3|       2|  100.0|2017-06-03|         61.0|         47.0| 51.0|\n",
      "|      Allen|          3|       2|   51.0|2017-06-04|         47.0|        100.0| 50.0|\n",
      "|      Allen|          3|       2|   50.0|2017-06-05|        100.0|         51.0| 39.0|\n",
      "|      Allen|          3|       2|   39.0|2017-06-06|         51.0|         50.0| 45.0|\n",
      "|      Allen|          3|       2|   45.0|2017-06-07|         50.0|         39.0| 47.0|\n",
      "|      Allen|          3|       2|   47.0|2017-06-08|         39.0|         45.0| 67.0|\n",
      "+-----------+-----------+--------+-------+----------+-------------+-------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.select('county_name','county_code','site_num','max_aqi','date_local','lag_2_max_aqi','lag_1_max_aqi','label').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df6 = df5.withColumn(\"trend1\", col(\"max_aqi\")/col(\"lag_1_max_aqi\")).withColumn(\"trend2\",col(\"max_aqi\")/col(\"lag_2_max_aqi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df7 = df6.filter('label > 0').na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "va = VectorAssembler(outputCol=\"features\", inputCols=df7.columns[6:]) \n",
    "df8 = va.transform(df7).select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|label|            features|\n",
      "+------------------+-----+--------------------+\n",
      "| 33.08112398116898| 23.0|(44,[0,1,3,4,11,1...|\n",
      "| 32.03715781569065| 31.0|(44,[0,1,3,4,11,1...|\n",
      "|33.703216778991056| 41.0|(44,[0,1,3,4,11,1...|\n",
      "|31.880766624880106| 27.0|(44,[0,1,3,4,11,1...|\n",
      "|28.045838637613528| 26.0|(44,[0,1,3,4,11,1...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 17.0039\n",
      "CPU times: user 113 ms, sys: 8.16 ms, total: 121 ms\n",
      "Wall time: 9min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = df8.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(featuresCol='features', numTrees=100)\n",
    "\n",
    "# Chain indexer and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "#rfModel = model.stages[1]\n",
    "#print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|label|            features|\n",
      "+------------------+-----+--------------------+\n",
      "|35.391528548542006| 47.0|(44,[0,1,3,4,11,1...|\n",
      "| 27.74044564019846| 16.0|(44,[0,1,3,4,11,1...|\n",
      "|27.876046629876203| 27.0|(44,[0,1,3,4,11,1...|\n",
      "|  31.0133962057185| 31.0|(44,[0,1,3,4,11,1...|\n",
      "|29.349164688496195| 26.0|(44,[0,1,3,4,11,1...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 18.1925\n",
      "CPU times: user 30.9 ms, sys: 17 ms, total: 47.8 ms\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = df8.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(featuresCol='features', numTrees=10)\n",
    "\n",
    "# Chain indexer and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "#rfModel = model.stages[1]\n",
    "#print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|label|            features|\n",
      "+------------------+-----+--------------------+\n",
      "| 32.58379812283956| 23.0|(44,[0,1,3,4,11,1...|\n",
      "| 25.57251823927943| 16.0|(44,[0,1,3,4,11,1...|\n",
      "|27.743214949548197| 27.0|(44,[0,1,3,4,11,1...|\n",
      "|28.793958275885394| 19.0|(44,[0,1,3,4,11,1...|\n",
      "|28.571704653482993| 34.0|(44,[0,1,3,4,11,1...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 16.7988\n",
      "CPU times: user 64.6 ms, sys: 12.3 ms, total: 77 ms\n",
      "Wall time: 3min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = df8.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(featuresCol='features', numTrees=50)\n",
    "\n",
    "# Chain indexer and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "#rfModel = model.stages[1]\n",
    "#print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: GBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|label|            features|\n",
      "+------------------+-----+--------------------+\n",
      "| 31.32354748679522| 23.0|(44,[0,1,3,4,11,1...|\n",
      "|26.079270957812813| 16.0|(44,[0,1,3,4,11,1...|\n",
      "|24.593950597865202| 27.0|(44,[0,1,3,4,11,1...|\n",
      "| 24.45541347385461| 19.0|(44,[0,1,3,4,11,1...|\n",
      "| 25.98360308059669| 34.0|(44,[0,1,3,4,11,1...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 15.6425\n",
      "CPU times: user 103 ms, sys: 17.3 ms, total: 121 ms\n",
      "Wall time: 9min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData3, testData3) = df8.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "gbt = GBTRegressor(featuresCol='features')\n",
    "\n",
    "# Chain indexer and forest in a Pipeline\n",
    "pipeline3 = Pipeline(stages=[gbt])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model3 = pipeline3.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions3 = model3.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions3.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator3 = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse3 = evaluator3.evaluate(predictions3)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
